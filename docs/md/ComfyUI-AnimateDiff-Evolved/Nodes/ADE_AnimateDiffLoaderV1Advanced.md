# AnimateDiff Loader (Advanced) [DEPRECATED] üé≠üÖêüÖì
## Documentation
- Class name: `ADE_AnimateDiffLoaderV1Advanced`
- Category: ``
- Output node: `False`

This node is designed for advanced loading of AnimateDiff models, offering enhanced control and customization options for the loading process. It is marked as deprecated, indicating that it may no longer be the preferred method for loading these models, but it remains available for use in specific scenarios where its advanced capabilities are required.
## Input types
### Required
- **`model`**
    - Comfy dtype: `MODEL`
    - Specifies the model to be loaded, serving as the core component for the AnimateDiff process.
    - Python dtype: `torch.nn.Module`
- **`latents`**
    - Comfy dtype: `LATENT`
    - Defines the latent space representations to be utilized in conjunction with the model.
    - Python dtype: `torch.Tensor`
- **`model_name`**
    - Comfy dtype: `COMBO[STRING]`
    - Determines the specific motion model to be loaded, allowing for targeted application of AnimateDiff functionalities.
    - Python dtype: `List[str]`
- **`unlimited_area_hack`**
    - Comfy dtype: `BOOLEAN`
    - A boolean flag that, when enabled, allows for bypassing certain constraints, potentially enhancing the flexibility of the AnimateDiff process.
    - Python dtype: `bool`
- **`context_length`**
    - Comfy dtype: `INT`
    - Specifies the length of the context used in the AnimateDiff process.
    - Python dtype: `int`
- **`context_stride`**
    - Comfy dtype: `INT`
    - Defines the stride of the context, affecting how the context is sampled or processed.
    - Python dtype: `int`
- **`context_overlap`**
    - Comfy dtype: `INT`
    - Indicates the overlap between consecutive contexts, which can affect the continuity and smoothness of the AnimateDiff output.
    - Python dtype: `int`
- **`context_schedule`**
    - Comfy dtype: `COMBO[STRING]`
    - Determines the scheduling of the context, which can influence the temporal dynamics of the AnimateDiff process.
    - Python dtype: `List[str]`
- **`closed_loop`**
    - Comfy dtype: `BOOLEAN`
    - A boolean flag indicating whether the AnimateDiff process should operate in a closed-loop manner, potentially affecting the model's behavior.
    - Python dtype: `bool`
- **`beta_schedule`**
    - Comfy dtype: `COMBO[STRING]`
    - Specifies the schedule for the beta parameter, influencing the behavior of the AnimateDiff model over time.
    - Python dtype: `List[str]`
## Output types
- **`model`**
    - Comfy dtype: `MODEL`
    - The loaded AnimateDiff model, ready for application within the specified context.
    - Python dtype: `torch.nn.Module`
- **`latent`**
    - Comfy dtype: `LATENT`
    - The latent space representations associated with the loaded model, facilitating further manipulation or application.
    - Python dtype: `torch.Tensor`
## Usage tips
- Infra type: `CPU`
- Common nodes: unknown


## Source code
```python
class AnimateDiffLoaderAdvanced_Deprecated:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "model": ("MODEL",),
                "latents": ("LATENT",),
                "model_name": (get_available_motion_models(),),
                "unlimited_area_hack": ("BOOLEAN", {"default": False},),
                "context_length": ("INT", {"default": 16, "min": 0, "max": 1000}),
                "context_stride": ("INT", {"default": 1, "min": 1, "max": 1000}),
                "context_overlap": ("INT", {"default": 4, "min": 0, "max": 1000}),
                "context_schedule": (ContextSchedules.LEGACY_UNIFORM_SCHEDULE_LIST,),
                "closed_loop": ("BOOLEAN", {"default": False},),
                "beta_schedule": (BetaSchedules.get_alias_list_with_first_element(BetaSchedules.SQRT_LINEAR),),
            },
        }

    RETURN_TYPES = ("MODEL", "LATENT")
    CATEGORY = ""
    FUNCTION = "load_mm_and_inject_params"

    def load_mm_and_inject_params(self,
            model: ModelPatcher,
            latents: Dict[str, torch.Tensor],
            model_name: str, unlimited_area_hack: bool,
            context_length: int, context_stride: int, context_overlap: int, context_schedule: str, closed_loop: bool,
            beta_schedule: str,
        ):
        # load motion module
        motion_model = load_motion_module_gen1(model_name, model)
        # get total frames
        init_frames_len = len(latents["samples"])  # deprecated - no longer used for anything lol
        # set injection params
        params = InjectionParams(
                unlimited_area_hack=unlimited_area_hack,
                apply_mm_groupnorm_hack=True,
                model_name=model_name,
                apply_v2_properly=False,
        )
        # set context settings
        params.set_context(
            ContextOptions(
                context_length=context_length,
                context_stride=context_stride,
                context_overlap=context_overlap,
                context_schedule=context_schedule,
                closed_loop=closed_loop,
            )
        )
        # inject for use in sampling code
        model = ModelPatcherAndInjector(model)
        model.motion_models = MotionModelGroup(motion_model)
        model.motion_injection_params = params

        # save model sampling from BetaSchedule as object patch
        # if autoselect, get suggested beta_schedule from motion model
        if beta_schedule == BetaSchedules.AUTOSELECT and not model.motion_models.is_empty():
            beta_schedule = model.motion_models[0].model.get_best_beta_schedule(log=True)
        new_model_sampling = BetaSchedules.to_model_sampling(beta_schedule, model)
        if new_model_sampling is not None:
            model.add_object_patch("model_sampling", new_model_sampling)

        del motion_model
        return (model, latents)

```
